# Word2Vec Training and Evaluation

This repository contains code and resources for training Word2Vec models using the Gensim library on the NLTK Brown corpus, and evaluating them against a set of manually judged word similarities and Google News embeddings.

## Project Description

This project trains Word2Vec models in two configurations: Continuous Bag of Words (CBOW) and Skip-Gram. These models are evaluated based on their ability to capture semantic similarities between words, compared against a benchmark provided by the pre-trained Google News embeddings.

## Setup

- Python Version: 3.8
- Libraries Required:
  - nltk
  - gensim
  - numpy
  - matplotlib
  - sklearn

## Repository Structure

- `main.py`: Contains the main script for training the Word2Vec models and performing evaluations.
- `A1_helper.py`: Helper module for reducing dimensions and plotting embeddings.
- `my_wv.txt`, `my_wv1.txt`: Word embedding files generated by the CBOW and Skip-Gram models, respectively.
- `sim.txt`: Manually created dataset for evaluating word pair similarities.
- `Report.pdf`: Detailed report on the methodologies and findings from this project.

## Instructions

To replicate the results, follow these steps:

1. Ensure Python 3.8 is installed along with all required libraries.
2. Run the `main.py` script to train the models and generate the embeddings.
3. Review the `Report.pdf` for an in-depth analysis of the training process, evaluation methods, and insights derived from the visualizations and correlation assessments.

## Visualization

The repository includes scripts to visualize the word embeddings. These visualizations compare the spatial relationships learned by the CBOW and Skip-Gram models and contrast them with those from Google News embeddings.

## Evaluation

The evaluation is conducted by comparing the cosine similarities of word pairs in the manually curated `sim.txt` with those produced by the embeddings. Results are quantified using Pearson correlation coefficients.

## Contributing

Contributions to this project are welcome. Please feel free to fork the repository and submit pull requests.
